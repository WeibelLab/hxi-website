---
# Documentation: https://wowchemy.com/docs/managing-content/

title: ICMI 2013 grand challenge workshop on multimodal learning analytics
subtitle: ''
summary: '<b>ICMI 2013</b><br/>This Grand Challenge evaluates predicting group dynamics and problem-solving success using multimodal data (speech, digital pen, video) from learning contexts. Results show reliable prediction of domain expertise and task outcomes across modalities, demonstrating that rich multimodal signals alone—independent of content analysis—can effectively assess group learning interactions.'
authors:
- Louis-Philippe Morency
- Sharon Oviatt
- Stefan Scherer
- Nadir Weibel
- Marcelo Worsley
doi: 10.1145/2522848.2534669
tags: []
categories: []
date: '2013-01-01'
lastmod: 2021-09-23T15:50:38-07:00
featured: false
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
publishDate: '2021-09-23T22:50:37.850526Z'
publication_types:
- '1'
abstract: "Advances in learning analytics are contributing new empirical findings, theories, methods, and metrics for understanding how students learn. It also contributes to improving pedagogical support for students' learning through assessment of new digital tools, teaching strategies, and curricula. Multimodal learning analytics (MMLA)[1] is an extension of learning analytics and emphasizes the analysis of natural rich modalities of communication across a variety of learning contexts. This MMLA Grand Challenge combines expertise from the learning sciences and machine learning in order to highlight the rich opportunities that exist at the intersection of these disciplines. As part of the Grand Challenge, researchers were asked to predict: (1) which student in a group was the dominant domain expert, and (2) which problems that the group worked on would be solved correctly or not. Analyses were based on a combination of speech, digital pen and video data. This paper describes the motivation for the grand challenge, the publicly available data resources and results reported by the challenge participants. The results demonstrate that multimodal prediction of the challenge goals: (1) is surprisingly reliable using rich multimodal data sources, (2) can be accomplished using any of the three modalities explored, and (3) need not be based on content analysis."
publication: '*Proceedings of the 15th ACM on International conference on multimodal interaction*'
---
